getwd() # make sure that the file is in the working directory

# load the data as a data.frame
birth <- read.csv(file = "chds_births.csv")

# summary of data
summary(birth)


# Smoke_number
# number (we create new descriptive groupings for number of cigarettes smoked per day)

num2 <- birth$number
# new categories for variable number
numnames <- c("never smoked", "up to half a pack", "half to full pack", "more than one pack")
for(ii in 0:9) {
  if(ii==0) {
    num2[num2 == ii] <- numnames[1]
  } 
  if(0 < ii & ii <= 2) {
    num2[num2 == ii] <- numnames[2]
  } 
  if(2 < ii & ii <= 4) {
    num2[num2 == ii] <- numnames[3]
  } else {
    num2[num2 == ii] <- numnames[4]
  }
}

birth$number <- num2 # replace in dataset

# Combine smoke and time into a single variable smoke (relabelling smoke):
newnames <- c("Never Smoked", "Still Smokes",
              "Smoked but quit during pregnancy", 
              "Smoked but quit before pregnancy") # create categories for new variables

# extract the corresponding columns
smoke <- birth$smoke

n <- length(smoke) # number of observations
newsmoke <- rep(NA, n)

for (ii in 1:n) {
  if (is.na(smoke[ii])) {
    newsmoke[ii] <- NA
  }
  else {
    for (jj in 0:3) {
      if (smoke[ii] == jj) {
        newsmoke[ii] <- newnames[jj+1]
      }
    }
  }
}
birth$smoke <- newsmoke

# locate the observations that have NA's in smoke
ind_smoke <- NA
for (ii in 1:length(birth$smoke)) {
  if (is.na(birth$smoke[ii])) {
    ind_smoke <- c(ind_smoke, ii)
  }
}
ind_smoke <- ind_smoke[2:length(ind_smoke)]

# locate the observations that have NA's in number
ind_number <- NA
for (ii in 1:length(birth$number)) {
  if (is.na(birth$number[ii])) {
    ind_number <- c(ind_number, ii)
  }
}
ind_number <- ind_number[2:length(ind_number)]

# Throw out the observations that have NA's in smoke and number
# note that observations that have NA's in smoke also have NA's in number
remove_smoke <- ind_number
birth <- birth[-remove_smoke,]

# create a new variable to combine smoke and number
# since they are correlated to each other
# note that nobody is in the category "Smoked up to half a pack but quit during pregnancy"
smoke_number <- birth$smoke
for (ii in 1:(length(birth$smoke))) {
  if (smoke_number[ii] != "Never Smoked") {
    if (birth$number[ii] == "up to half a pack") {
      if (smoke_number[ii] == "Smoked but quit before pregnancy") {
        smoke_number[ii] <- "Smoked up to half a pack but quit before pregnancy"
      }
      else {smoke_number[ii] <- "Still smokes up to half a pack"}
    }
    else if (birth$number[ii] == "half to full pack") {
      if (smoke_number[ii] == "Smoked but quit before pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit before pregnancy"
      }
      else if (smoke_number[ii] == "Smoked but quit during pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit during pregnancy"
      }
      else {smoke_number[ii] <- "Still smokes half to full pack"}
    }
    else {
      if (smoke_number[ii] == "Smoked but quit before pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit before pregnancy"
      }
      else if (smoke_number[ii] == "Smoked but quit during pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit during pregnancy"
      }
      else {smoke_number[ii] <- "Still smokes more than one pack"}
    }
  }
}


birth$smoke_number <- factor(smoke_number)



# Combine other and mixed in feth and call it other
for (ii in 1:length(birth$feth)) {
  if (!is.na(birth$feth[ii])) {
    if(birth$feth[ii] == 10) {
      birth$feth[ii] <- 9
    }
  }
}

# Combine other and mixed in meth and call it other
for (ii in 1:length(birth$meth)) {
  if (!is.na(birth$meth[ii])) {
    if(birth$meth[ii] == 10) {
      birth$meth[ii] <- 9
    }
  }
}


#**************************************************************
# convert categorical variables to factors

# convert meth to non-numeric categorical variable
meth2 <- birth$meth
length(meth2)
# "levels" of variable meth
methnames <- c("Caucasian","Mexican", "African-American","Asian", "Other")
# assign "Caucasian" level to values less than or equal to 5
# otherwise assign levels based on order in methnames vector
for(ii in 0:9) {
  if(ii<=5){
    meth2[meth2 == ii] <- "Caucasian"
  } else {
    meth2[meth2 == ii] <- methnames[ii-4]
  }
}
meth2 <- factor(meth2, levels = methnames) # order levels based on methnames
levels(meth2)
birth$meth <- meth2 # replace in dataset
############################################
# convert med to categorical variables
med2 <- birth$med
# "levels" of variable med
mednames <- c("elementary school", "middle school", "high school", "high school + trade", "high school + some college", "college grad", "trade school", "high school unclear")
med2 <- mednames[birth$med+1]
med2 <- factor(med2, levels = mednames) # order levels based on mednames
levels(med2)
birth$med <- med2 # replace in dataset
##########################################
# convert feth to categorical variables
feth2 <- birth$feth
# "levels" of variable feth
fethnames <- c("Caucasian","Mexican", "African-American","Asian", "Other")
# assign "Caucasian" level to values less than or equal to 5
# otherwise assign levels based on order in fethnames vector
for(ii in 0:9) {
  if(ii<=5){
    feth2[feth2 == ii] <- "Caucasian"
  } else {
    feth2[feth2 == ii] <- fethnames[ii-4]
  }
}
feth2 <- factor(feth2, levels = fethnames) # order levels based on methnames
levels(feth2)
birth$feth <- feth2 # replace in dataset
############################################
# convert fed to categorical variables
fed2 <- birth$fed
# "levels" of variable fed
fednames <- c("elementary school", "middle school", "high school", "high school + trade", "high school + some college", "college grad", "trade school", "high school unclear")
fed2 <- fednames[birth$fed+1]
fed2 <- factor(fed2, levels = fednames) # order levels based on fednames
levels(fed2)
birth$fed <- fed2 # replace in dataset

################################################################################
# marital
marital <- birth$marital
maritalnames <- c("married", "legally separated", "divorced", "widowed",
                  "never married") # new values
# encode the factor
marital2 <- rep(NA, length(marital))
for (ii in 1:5) {
  marital2[marital == ii] <- maritalnames[ii]
}
marital2 <- factor(marital2, levels = maritalnames)
birth$marital <- marital2
######################################################################
# income
income <- birth$income
incomenames <- c("under 2500", "2500-4999", "5000-7499", "7500-9999",
                 "10000-12499", "12500-14999", "15000-17499",
                 "17500-19999", "20000-22499", "over 22500") # new values
# encode the factor
income2 <- incomenames[income+1]
income2 <- factor(income2, levels = incomenames)
birth$income <- income2
############################################################

implies that we include any of these three factors into our models, then it is probable that our models will be biased because there are too many unavailable data and we do not know why they are unavailable; as a result, any model including any of these three factors will not be representative of the **entire population**. Therefore, based on the given dataset, it is reasonable not to consider these three factors. **TBC**
#********************************************************************************

# throw out fht, fwt and income
birth <- birth[,-c(12, 13, 15)]

# Check how many observations contain NA's
n <- length(birth$wt) # number of rows
count <- 0 # initialize count of rows with at least one NA
for (ii in 1:n) {
  if(sum(is.na(birth[ii,])) >= 1) {
    count = count + 1
  }
}
total_NA_rows <- count
total_NA_rows





# throw out the variable time
birth <- birth[,-14]



# Combine mht and mwt to create a new variable BMI
# BMI is called Body Mass Index, which is calculated by weight in kg / height^2 in m
# Convert mht and mwt to standard metric
lbs_to_kg <- 0.453592
birth$mwt <- lbs_to_kg * birth$mwt
inch_to_meter <- 0.0254
birth$mht <- inch_to_meter * birth$mht

# Create BMI variable
mht <- birth$mht
mwt <- birth$mwt
BMI <- mwt / mht^2
birth$BMI <- BMI


# throw out mht and mwt
birth <- birth[,-c(7, 8)]

# throw out smoke and number
birth <- birth[, -c(11, 12)]
# Modify the variables smoke and number so that we can obtain all coefficients' values



# Want to count how many rows have meth=feth
count.eth <- 0
for (ii in 1:length(birth$meth)) {
  if ((is.na(birth$feth[ii])==FALSE) & is.na(birth$meth[ii])==FALSE){
    if (birth$meth[ii]<=5) {
      if (birth$feth[ii]<=5){
        count.eth <- count.eth+1
      }
    }
    else {
      if (birth$meth[ii]==birth$feth[ii]){
        count.eth <- count.eth+1
      }
    }
  }
}
count.eth

# we assume fathers and mothers have the same ethnicity background
# based on the majority of the dataset
# deal with the NA's in meth (justification)
for (ii in 1:length(birth$meth)) {
  if(is.na(birth$meth)[ii]) {
    birth$meth[ii] <- birth$feth[ii]
  }
}

# deal with the NA's in feth (justification needed)
for (ii in 1:length(birth$feth)) {
  if(is.na(birth$feth)[ii]) {
    birth$feth[ii] <- birth$meth[ii]
  }
}






# locate the observations that have NA's in gestation
ind_gestation <- NA
for (ii in 1:length(birth$gestation)) {
  if (is.na(birth$gestation[ii])) {
    ind_gestation <- c(ind_gestation, ii)
  }
}
ind_gestation <- ind_gestation[2:length(ind_gestation)]

# locate the observations that have NA's in mage
ind_mage <- NA
for (ii in 1:length(birth$mage)) {
  if (is.na(birth$mage[ii])) {
    ind_mage <- c(ind_mage, ii)
  }
}
ind_mage <- ind_mage[2:length(ind_mage)]

# locate the observations that have NA's in med
ind_med <- NA
for (ii in 1:length(birth$med)) {
  if (is.na(birth$med[ii])) {
    ind_med <- c(ind_med, ii)
  }
}
ind_med <- ind_med[2:length(ind_med)]

# locate the observations that have NA's in fage
ind_fage <- NA
for (ii in 1:length(birth$fage)) {
  if (is.na(birth$fage[ii])) {
    ind_fage <- c(ind_fage, ii)
  }
}
ind_fage <- ind_fage[2:length(ind_fage)]

# locate the observations that have NA's in fed
ind_fed <- NA
for (ii in 1:length(birth$fed)) {
  if (is.na(birth$fed[ii])) {
    ind_fed <- c(ind_fed, ii)
  }
}
ind_fed <- ind_fed[2:length(ind_fed)]

# locate the observations that have NA's in marital
ind_marital <- NA
for (ii in 1:length(birth$marital)) {
  if (is.na(birth$marital[ii])) {
    ind_marital <- c(ind_marital, ii)
  }
}
ind_marital <- ind_marital[2:length(ind_marital)]


# locate the observations that have NA's in BMI
ind_BMI <- NA
for (ii in 1:length(birth$BMI)) {
  if (is.na(birth$BMI[ii])) {
    ind_BMI <- c(ind_BMI, ii)
  }
}
ind_BMI <- ind_BMI[2:length(ind_BMI)]

missing <- c(ind_gestation, ind_mage, ind_BMI, ind_marital, ind_fage, ind_fed, ind_med)
missing

# remove missing observations

# first remove duplicated numbers in the missing list
m <- length(missing)
new_missing <- NA
for (ii in 1:m) {
  if (missing[ii] %in% new_missing == FALSE) {
    new_missing <- c(new_missing, missing[ii])
  }
}
new_missing <- new_missing[2:length(new_missing)]
new_missing


# remove observations containing NA's
birth <- birth[-new_missing,]
summary(birth)







# Nov 26th

# (pre-diagnostics) 
summary(birth) # summary of data
# Discuss NA's -> Methods to deal with them 
# factor of categorical variables
# regrouping of some variables (smoke & time, numbers, BMI)
# deal with the NA's in smoke and number

# Pair plots of weights and other continuous variables
pairs(~ wt + gestation + parity + mage + BMI + fage, 
      pch = 19,
      cex = 0.05,
      data = birth)


# Automated model selection
# Minimal model
M0 <- lm(wt ~ 1, data = birth)
summary(M0)


# new maximal model
Mmaxnew <- lm(wt ~ (.-fed - med - feth - meth - marital - smoke_number)^2 
              + smoke_number + feth + meth + fed + med + marital 
              + I(gestation^2), data = birth)
summary(Mmaxnew)

beta.maxnew <- coef(Mmaxnew)
names(beta.maxnew)[is.na(beta.maxnew)]
anyNA(coef(Mmaxnew))


# Automated Model Selection
# Forward selection
system.time({ # time the calculation
  Mfwd <- step(object = M0, # starting point model
               scope = list(lower = M0, upper = Mmaxnew), # smallest and largest model
               direction = "forward",
               trace = FALSE) # trace prints out information
})

# Backward elimination
system.time({
  Mback <- step(object = Mmaxnew, # starting point model
                scope = list(lower = M0, upper = Mmaxnew),
                direction = "backward", trace = FALSE)
})

# Stepwise selection
Mstart <- lm(wt ~ ., data = birth)
system.time({
  Mstep <- step(object = Mstart,
                scope = list(lower = M0, upper = Mmaxnew),
                direction = "both", trace = FALSE)
})














# Numerical Analysis
# models to compare
M1 <- Mfwd
M2 <- Mstep
Mnames <- expression(M[FWD], M[STEP])
# Cross-validation setup
nreps <- 2e3 # number of replications
ntot <- nrow(birth) # total number of observations
ntrain <- 500 # size of training set
ntest <- ntot-ntrain # size of test set
mspe1 <- rep(NA, nreps) # sum-of-square errors for each CV replication
mspe2 <- rep(NA, nreps)
logLambda <- rep(NA, nreps) # log-likelihod ratio statistic for each replication
system.time({
  for(ii in 1:nreps) {
    if(ii%%400 == 0) message("ii = ", ii)
    # randomly select training observations
    train.ind <- sample(ntot, ntrain) # training observations
    # refit the models on the subset of training data; ?update for details!
    M1.cv <- update(M1, subset = train.ind)
    M2.cv <- update(M2, subset = train.ind)
    # out-of-sample residuals for both models
    # that is, testing data - predictions with training parameters
    M1.res <- birth$wt[-train.ind] -
      predict(M1.cv, newdata = birth[-train.ind,])
    M2.res <- birth$wt[-train.ind] -
      predict(M2.cv, newdata = birth[-train.ind,])
    # mean-square prediction errors
    mspe1[ii] <- mean(M1.res^2)
    mspe2[ii] <- mean(M2.res^2)
    # out-of-sample likelihood ratio
    M1.sigma <- sqrt(sum(resid(M1.cv)^2)/ntrain) # MLE of sigma
    M2.sigma <- sqrt(sum(resid(M2.cv)^2)/ntrain)
    # since res = y - pred, dnorm(y, pred, sd) = dnorm(res, 0, sd)
    logLambda[ii] <- sum(dnorm(M1.res, mean = 0, sd = M1.sigma, log = TRUE))
    logLambda[ii] <- logLambda[ii] -
      sum(dnorm(M2.res, mean = 0, sd = M2.sigma, log = TRUE))
  }
})


# Different residual plots
# plot setup
cex <- .8
pch <- 16
par(mfrow = c(1,2), mar = c(4,4,.1,.1))

# residuals for M1 and M2
res1 <- residuals(M1)
res2 <- residuals(M2)

# plot ordinary residuals for M1
plot(predict(M1), residuals(M1), pch = pch, cex = cex, col = "black", 
     main = "M1 Residual Plot ")
abline(h = 0, col = "red", lty = 2) # horizontal line

# plot ordinary residuals for M1
plot(predict(M2), residuals(M2), pch = pch, cex = cex, col = "black", 
     main = "M2 Residual Plot ")
abline(h = 0, col = "red", lty = 2) # horizontal line


# extract sigma.hat for both M1 and M2
sigma.hat1 <- sigma(M1)
sigma.hat2 <- sigma(M2)

# QQ-plot for M1
qqnorm(res1, main = "M1 QQ-Plot", cex = cex, pch = pch)
qqline(res1, col = "red", lty = 2)

# QQ-plot for M2
qqnorm(res2, main = "M2 QQ-Plot", cex = cex, pch = pch)
qqline(res2, col = "red", lty = 2)




# Dec 1st 

# Predicted Value vs Residuals and Leverages for M1

h1 <- hatvalues(M1)  # HAT Matrix
stan.res1 <- res1/sigma.hat1 # Standardized residuals for M1

# PRESS residuals
press1 <- res1/(1-h1)

# DFFITS residuals
dfts1 <- dffits(M1) # the R way
# standardize each of these such that they are identical at the average leverage value
p1 <- length(coef(M1))
n1 <- nobs(M1)
hbar1 <- p1/n1 # average leverage
press1 <- press1*(1-hbar)/sigma.hat1 # at h1 = hbar1, press1 = stan.res1
dfts1 <- dfts1*(1-hbar)/sqrt(hbar1) # at h1 = hbar1, dfts1 = stan.res1

# plot all residuals
# against predicted values
plot(predict(M1), rep(0, length(predict(M1))), type = "n", # empty plot to get the axis range
     ylim = range(stan.res1, press1, dfts1), cex.axis = cex,
     xlab = "M1 Predicted Values", ylab = "M1 Residuals")
# dotted line connecting each observations residuals for better visibility
segments(x0 = predict(M1),
         y0 = pmin(stan.res1, press1, dfts1),
         y1 = pmax(stan.res1, press1, dfts1),
         lty = 2)
points(predict(M1), stan.res1, pch = 21, bg = "black", cex = cex)
points(predict(M1), press1, pch = 21, bg = "red", cex = cex)
points(predict(M1), dfts1, pch = 21, bg = "orange", cex = cex)
# against leverages
plot(h1, rep(0, length(predict(M1))), type = "n", cex.axis = cex,
     ylim = range(stan.res1, press1, dfts1),
     xlab = "Leverages", ylab = "Residuals")
segments(x0 = h1,
         y0 = pmin(stan.res1, press1, dfts1),
         y1 = pmax(stan.res1, press1, dfts1),
         lty = 2)
points(h1, stan.res1, pch = 21, bg = "black", cex = cex)
points(h1, press1, pch = 21, bg = "red", cex = cex)
points(h1, dfts1, pch = 21, bg = "orange", cex = cex)
abline(v = hbar1, col = "grey60", lty = 2)
legend("topright", legend = c("Standardized", "PRESS", "DFFITS"),
       pch = 21, pt.bg = c("black", "red", "orange"), title = "Residual Type:",
       cex = cex, pt.cex = cex)


# cook’s distance vs. leverage for M1
D1 <- cooks.distance(M1)
# flag some of the points
infl.ind1 <- which.max(D1) # top influence point
lev.ind1 <- h1 > 2*hbar1 # leverage more than 2x the average
clrs1 <- rep("black", len = n1)
clrs1[lev.ind1] <- "blue"
clrs1[infl.ind1] <- "red"
plot(h1, D1, xlab = "M1 Leverage", ylab = "M1 Cook’s Influence Measure",
     pch = 21, bg = clrs1, cex = cex, cex.axis = cex)
p1 <- length(coef(M1))
n1 <- nrow(birth)
hbar1 <- p1/n1 # average leverage
abline(v = 2*hbar1, col = "grey60", lty = 2) # 2x average leverage
legend("topleft", legend = c("High Leverage", "High Influence"), pch = 21,
       pt.bg = c("blue", "red"), cex = cex, pt.cex = cex)


####################################################################

# Predicted Value vs Residuals and Leverages for M2
h2 <- hatvalues(M2)  # HAT Matrix for M2
stan.res2 <- res1/sigma.hat2 # Standardized residuals for M2

# PRESS residuals
press2 <- res2/(1-h2)

# DFFITS residuals
dfts2 <- dffits(M2) 
# standardize each of these such that they are identical at the average leverage value
p2 <- length(coef(M2))
n2 <- nobs(M2)
hbar2 <- p2/n2 # average leverage
press2 <- press2*(1-hbar2)/sigma.hat2 # at h = hbar2, press2 = stan.res
dfts2 <- dfts2*(1-hbar2)/sqrt(hbar2) # at h = hbar2, dfts2 = stan.res

# plot all residuals
par(mfrow = c(1,2), mar = c(4,4,.1,.1))
# against predicted values
plot(predict(M2), rep(0, length(predict(M2))), type = "n", # empty plot to get the axis range
     ylim = range(stan.res2, press2, dfts2), cex.axis = cex,
     xlab = "M2 Predicted Values", ylab = "M2 Residuals")
# dotted line connecting each observations residuals for better visibility
segments(x0 = predict(M2),
         y0 = pmin(stan.res2, press2, dfts2),
         y1 = pmax(stan.res2, press2, dfts2),
         lty = 2)
points(predict(M2), stan.res2, pch = 21, bg = "black", cex = cex)
points(predict(M2), press2, pch = 21, bg = "red", cex = cex)
points(predict(M2), dfts2, pch = 21, bg = "orange", cex = cex)
# against leverages
plot(h, rep(0, length(predict(M2))), type = "n", cex.axis = cex,
     ylim = range(stan.res2, press2, dfts2),
     xlab = "Leverages", ylab = "Residuals")
segments(x0 = h2,
         y0 = pmin(stan.res2, press2, dfts2),
         y1 = pmax(stan.res2, press2, dfts2),
         lty = 2)
points(h2, stan.res2, pch = 21, bg = "black", cex = cex)
points(h2, press2, pch = 21, bg = "red", cex = cex)
points(h2, dfts2, pch = 21, bg = "orange", cex = cex)
abline(v = hbar2, col = "grey60", lty = 2)
legend("topright", legend = c("Standardized", "PRESS", "DFFITS"),
       pch = 21, pt.bg = c("black", "red", "orange"), title = "Residual Type:",
       cex = cex, pt.cex = cex)


# cook’s distance vs. leverage for M2
D2 <- cooks.distance(M2)
# flag some of the points
infl.ind2 <- which.max(D2) # top influence point
lev.ind2 <- h2 > 2*hbar2 # leverage more than 2x the average
clrs2 <- rep("black", len = n1)
clrs2[lev.ind2] <- "blue"
clrs2[infl.ind2] <- "red"
par(mfrow = c(1,1), mar = c(4,4,1,1))
cex <- .8
plot(h2, D2, xlab = "M2 Leverage", ylab = "M2 Cook’s Influence Measure",
     pch = 21, bg = clrs2, cex = cex, cex.axis = cex)
p2 <- length(coef(M2))
n2 <- nrow(birth)
hbar2 <- p2/n2 # average leverage
abline(v = 2*hbar2, col = "grey60", lty = 2) # 2x average leverage
legend("topleft", legend = c("High Leverage", "High Influence"), pch = 21,
       pt.bg = c("blue", "red"), cex = cex, pt.cex = cex)






#####################################################################

# plot rMSPE and out-of-sample log(Lambda)
boxplot(x = list(sqrt(mspe1), sqrt(mspe2)), names = Mnames, cex = .7,
        ylab = expression(sqrt(MSPE)), col = c("yellow", "orange"))

hist(logLambda, breaks = 50, freq = FALSE,
     xlab = expression(Lambda^{test}),
     main = "", cex = .7)
abline(v = mean(logLambda), col = "red") # average value

# Akaike Information Criterion
AIC1 <- AIC(M1)
AIC2 <- AIC(M2)
AIC <- c(AIC1, AIC2)
AIC

# PRESS Statistics
# PRESS statistics
press1 <- resid(M1)/(1-hatvalues(M1)) # M1
press2 <- resid(M2)/(1-hatvalues(M2)) # M2

# display results
disp <- rbind(AIC = c(AIC1, AIC2),
              PRESS = c(sum(press1^2), sum(press2^2)))
colnames(disp) <- Mnames
disp # both metrics favor M2

# plot PRESS statistics
par(mar = c(3, 6, 1, 1))
boxplot(x = list(abs(press1), abs(press2)), names = Mnames,
        ylab = expression(group("|", PRESS[i], "|")),
        col = c("yellow", "orange"))


































