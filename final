---
title: "STAT 331 Project"
author: "Francis Han; Catherine Wang"
date: "`r format(Sys.Date(), format = '%B %d, %Y')`"
fontsize: 12pt
link-citations: yes
linkcolor: blue
output: 
   pdf_document:
     number_sections: TRUE
---

\newcommand{\var}{\mathrm{var}}

# Summary
This project is aimed at exploring the relationship between healthy male single-fetus birth weight and some explanatory variables based on the dataset containing information about 1236 healthy male single-fetus births of women enrolled in the Kaiser Foundation Health Plan in the San Francisco/East Bay area between 1960-1967. The entire statistical analysis was performed in the following steps: data cleaning, imputation, pre-fitting data diagnostics, automated model selection, model diagnostics of two candidate models and discussion of the results of the chosen model. We concluded that the significant explanatory variables for healthy male single-fetus birth weight are: the length of the gestation period, the total number of previous pregnancies, the father's ethnicity, the mother's age, the mother's height and weight, whether the mother smoked during pregnancy and the number of cigarettes smoked per day by the mother when she was smoking.

# Model Selection
## Deal with NA's in fht, fwt and income:
To begin with, we had a look at the summary of the dataset(see \ref{summary}). It is obvious that father's height (fht), father's weight (fwt) and the family yearly income (income) contain "too many" NA's. It implies that if we include any of these three factors into our models, then it is probable that our models will be highly biased because there are too many unavailable data and we do not know why they are unavailable; as a result, any model including any of these three factors will not be representative of the *entire population*. Therefore, based on the given dataset, it is reasonable to remove these three variables (see \ref{NA}). After removing these three variables, we counted how many observations have NA's (see \ref{countNA}). It turned out that there were only 119 observations containing NA's, which account for less than 10% of the entire dataset.

## Creating the New Variable smoke_number:
We noticed that the three variables indicating 1) whether the mother smoked during pregnancy (*smoke*); 2) time since the mother quit smoking before pregnancy (*time*); 3) number of cigarettes smoked per day by the mother when she was smoking (*number*) are highly correlated with each other and are divided into too many categories. Therefore, we decided to create a new variable that could store all information from these three variables so that after we fit the models, we will get more meaningful coefficients. 

First, we regrouped the variable *number* into four categories: never smoked, up to half a pack, half to full pack, and more than one pack (see \ref{number}). Then, we regrouped the variable *smoke* in terms of the variable *time* so that the variable *smoke* can store information from both the original *smoke* and *time* (see \ref{smoketime}). After this, we realized that in total, there are 21 NA's in smoke and number. Thus, we removed the observations that have NA's in smoke and number (see \ref{removesmokenumber}). At the end, we created a new variable named *smoke_number* which indicates when the mother quit smoking and how many cigarettes the mother smoked when she was smoking (see \ref{smoke_number}), where we created new categories: Never smoked, Smoked more than half and pack but quit before pregnancy, Smoke more than half a pack but quit during pregnancy, Smoked up to half a pack but quit before pregnancy, Still smokes half to full pack, Still smokes more than one pack, and Still smokes up to half a pack. And now that we have a new variable, we could throw out the original *smoke*, *time* and *number* (see \ref{smoketimenumber}). 

## Create the New Variable: BMI
We realized that Body Mass Index (BMI) combines information mother's height(mht) and mother's weight(mwt), and is a better representation of the mother's health status than just height and weight separately (see \ref{BMI}). After this, we removed the original variables mht and mwt (see \ref{removemhtmwt}).

## Imputing the Variables mother's ethnicity (meth) and father's ethnicity(feth)
First we realized that there are subcategories in each variable that account for a very small portion of the entire observations, such as the subcategories *mixed* and *other*. Therefore, we decided to combine them to a new variable *other* for each of meth and feth (see \ref{othermixed}). After this, we realized that there are NA's in both feth and meth; besides, we checked that the majority of parents have the same ethnicity (see \ref{countethnicity}). Plus, there is only a small number of observations that have NA's in meth and feth. Hence, for the missing NA's in meth and feth, it is reasonable to replace them with the corresponding ethnicity of the other parent (see \ref{ethNA}). 

## Factor all Categorical Variables
We converted all categorical variables into factors. (see \ref{factor}).

## Deal with observations that contain NA's
At this point, we noted that there are still NA's in some observations. As mentioned in Section 1.1, totally there were only 119 observations containig NA's. Since they account for less than 10% of the dataset, it is acceptable to remove them from the dataset without creating much biase (see \ref{removeNA}). 

## Pair Plots
Now that we have cleaned the dataset, we did pre-fitting data diagnostics. We constructed the pair plot of birth weight(wt) with other continuous numerical variables (see \ref{pairplot}). We noted that there might be a quadratic relation between birth weight (wt) and the length of the gestation period (gestation), which will be checked during future model selection. 

```{r, echo = FALSE}

# load the data as a data.frame
birth <- read.csv(file = "chds_births.csv")

# summary of data



# Smoke_number
# number (we create new descriptive groupings for number of cigarettes smoked per day)

num2 <- birth$number
# new categories for variable number
numnames <- c("never smoked", "up to half a pack", "half to full pack", "more than one pack")
for(ii in 0:9) {
  if(ii==0) {
    num2[num2 == ii] <- numnames[1]
  } 
  if(0 < ii & ii <= 2) {
    num2[num2 == ii] <- numnames[2]
  } 
  if(2 < ii & ii <= 4) {
    num2[num2 == ii] <- numnames[3]
  } else {
    num2[num2 == ii] <- numnames[4]
  }
}

birth$number <- num2 # replace in dataset

# Combine smoke and time into a single variable smoke (relabelling smoke):
newnames <- c("Never Smoked", "Still Smokes",
              "Smoked but quit during pregnancy", 
              "Smoked but quit before pregnancy") # create categories for new variables

# extract the corresponding columns
smoke <- birth$smoke

n <- length(smoke) # number of observations
newsmoke <- rep(NA, n)

for (ii in 1:n) {
  if (is.na(smoke[ii])) {
    newsmoke[ii] <- NA
  }
  else {
    for (jj in 0:3) {
      if (smoke[ii] == jj) {
        newsmoke[ii] <- newnames[jj+1]
      }
    }
  }
}
birth$smoke <- newsmoke

# locate the observations that have NA's in smoke
ind_smoke <- NA
for (ii in 1:length(birth$smoke)) {
  if (is.na(birth$smoke[ii])) {
    ind_smoke <- c(ind_smoke, ii)
  }
}
ind_smoke <- ind_smoke[2:length(ind_smoke)]

# locate the observations that have NA's in number
ind_number <- NA
for (ii in 1:length(birth$number)) {
  if (is.na(birth$number[ii])) {
    ind_number <- c(ind_number, ii)
  }
}
ind_number <- ind_number[2:length(ind_number)]

# Throw out the observations that have NA's in smoke and number
# note that observations that have NA's in smoke also have NA's in number
remove_smoke <- ind_number
birth <- birth[-remove_smoke,]

# create a new variable to combine smoke and number
# since they are correlated to each other
# note that nobody is in the category "Smoked up to half a pack but quit during pregnancy"
smoke_number <- birth$smoke
for (ii in 1:(length(birth$smoke))) {
  if (smoke_number[ii] != "Never Smoked") {
    if (birth$number[ii] == "up to half a pack") {
      if (smoke_number[ii] == "Smoked but quit before pregnancy") {
        smoke_number[ii] <- "Smoked up to half a pack but quit before pregnancy"
      }
      else {smoke_number[ii] <- "Still smokes up to half a pack"}
    }
    else if (birth$number[ii] == "half to full pack") {
      if (smoke_number[ii] == "Smoked but quit before pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit before pregnancy"
      }
      else if (smoke_number[ii] == "Smoked but quit during pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit during pregnancy"
      }
      else {smoke_number[ii] <- "Still smokes half to full pack"}
    }
    else {
      if (smoke_number[ii] == "Smoked but quit before pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit before pregnancy"
      }
      else if (smoke_number[ii] == "Smoked but quit during pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit during pregnancy"
      }
      else {smoke_number[ii] <- "Still smokes more than one pack"}
    }
  }
}


birth$smoke_number <- factor(smoke_number)



# Combine other and mixed in feth and call it other
for (ii in 1:length(birth$feth)) {
  if (!is.na(birth$feth[ii])) {
    if(birth$feth[ii] == 10) {
      birth$feth[ii] <- 9
    }
  }
}

# Combine other and mixed in meth and call it other
for (ii in 1:length(birth$meth)) {
  if (!is.na(birth$meth[ii])) {
    if(birth$meth[ii] == 10) {
      birth$meth[ii] <- 9
    }
  }
}


#**************************************************************
# convert categorical variables to factors

# convert meth to non-numeric categorical variable
meth2 <- birth$meth
# "levels" of variable meth
methnames <- c("Caucasian","Mexican", "African-American","Asian", "Other")
# assign "Caucasian" level to values less than or equal to 5
# otherwise assign levels based on order in methnames vector
for(ii in 0:9) {
  if(ii<=5){
    meth2[meth2 == ii] <- "Caucasian"
  } else {
    meth2[meth2 == ii] <- methnames[ii-4]
  }
}
meth2 <- factor(meth2, levels = methnames) # order levels based on methnames
birth$meth <- meth2 # replace in dataset
############################################
# convert med to categorical variables
med2 <- birth$med
# "levels" of variable med
mednames <- c("elementary school", "middle school", "high school", "high school + trade", "high school + some college", "college grad", "trade school", "high school unclear")
med2 <- mednames[birth$med+1]
med2 <- factor(med2, levels = mednames) # order levels based on mednames
birth$med <- med2 # replace in dataset
##########################################
# convert feth to categorical variables
feth2 <- birth$feth
# "levels" of variable feth
fethnames <- c("Caucasian","Mexican", "African-American","Asian", "Other")
# assign "Caucasian" level to values less than or equal to 5
# otherwise assign levels based on order in fethnames vector
for(ii in 0:9) {
  if(ii<=5){
    feth2[feth2 == ii] <- "Caucasian"
  } else {
    feth2[feth2 == ii] <- fethnames[ii-4]
  }
}
feth2 <- factor(feth2, levels = fethnames) # order levels based on methnames
birth$feth <- feth2 # replace in dataset
############################################
# convert fed to categorical variables
fed2 <- birth$fed
# "levels" of variable fed
fednames <- c("elementary school", "middle school", "high school", "high school + trade", "high school + some college", "college grad", "trade school", "high school unclear")
fed2 <- fednames[birth$fed+1]
fed2 <- factor(fed2, levels = fednames) # order levels based on fednames
birth$fed <- fed2 # replace in dataset

################################################################################
# marital
marital <- birth$marital
maritalnames <- c("married", "legally separated", "divorced", "widowed",
                  "never married") # new values
# encode the factor
marital2 <- rep(NA, length(marital))
for (ii in 1:5) {
  marital2[marital == ii] <- maritalnames[ii]
}
marital2 <- factor(marital2, levels = maritalnames)
birth$marital <- marital2
######################################################################
# income
income <- birth$income
incomenames <- c("under 2500", "2500-4999", "5000-7499", "7500-9999",
                 "10000-12499", "12500-14999", "15000-17499",
                 "17500-19999", "20000-22499", "over 22500") # new values
# encode the factor
income2 <- incomenames[income+1]
income2 <- factor(income2, levels = incomenames)
birth$income <- income2
############################################################
#********************************************************************************

# throw out fht, fwt and income
birth <- birth[,-c(12, 13, 15)]

# Check how many observations contain NA's
n <- length(birth$wt) # number of rows
count <- 0 # initialize count of rows with at least one NA
for (ii in 1:n) {
  if(sum(is.na(birth[ii,])) >= 1) {
    count = count + 1
  }
}
total_NA_rows <- count

# throw out the variable time
birth <- birth[,-14]

# Combine mht and mwt to create a new variable BMI
# BMI is called Body Mass Index, which is calculated by weight in kg / height^2 in m
# Convert mht and mwt to standard metric
lbs_to_kg <- 0.453592
birth$mwt <- lbs_to_kg * birth$mwt
inch_to_meter <- 0.0254
birth$mht <- inch_to_meter * birth$mht

# Create BMI variable
mht <- birth$mht
mwt <- birth$mwt
BMI <- mwt / mht^2
birth$BMI <- BMI


# throw out mht and mwt
birth <- birth[,-c(7, 8)]

# throw out smoke and number
birth <- birth[, -c(11, 12)]
# Modify the variables smoke and number so that we can obtain all coefficients' values




# we assume fathers and mothers have the same ethnicity background
# based on the majority of the dataset
# deal with the NA's in meth (justification)
for (ii in 1:length(birth$meth)) {
  if(is.na(birth$meth)[ii]) {
    birth$meth[ii] <- birth$feth[ii]
  }
}

# deal with the NA's in feth (justification needed)
for (ii in 1:length(birth$feth)) {
  if(is.na(birth$feth)[ii]) {
    birth$feth[ii] <- birth$meth[ii]
  }
}

# locate the observations that have NA's in gestation
ind_gestation <- NA
for (ii in 1:length(birth$gestation)) {
  if (is.na(birth$gestation[ii])) {
    ind_gestation <- c(ind_gestation, ii)
  }
}
ind_gestation <- ind_gestation[2:length(ind_gestation)]

# locate the observations that have NA's in mage
ind_mage <- NA
for (ii in 1:length(birth$mage)) {
  if (is.na(birth$mage[ii])) {
    ind_mage <- c(ind_mage, ii)
  }
}
ind_mage <- ind_mage[2:length(ind_mage)]

# locate the observations that have NA's in med
ind_med <- NA
for (ii in 1:length(birth$med)) {
  if (is.na(birth$med[ii])) {
    ind_med <- c(ind_med, ii)
  }
}
ind_med <- ind_med[2:length(ind_med)]

# locate the observations that have NA's in fage
ind_fage <- NA
for (ii in 1:length(birth$fage)) {
  if (is.na(birth$fage[ii])) {
    ind_fage <- c(ind_fage, ii)
  }
}
ind_fage <- ind_fage[2:length(ind_fage)]

# locate the observations that have NA's in fed
ind_fed <- NA
for (ii in 1:length(birth$fed)) {
  if (is.na(birth$fed[ii])) {
    ind_fed <- c(ind_fed, ii)
  }
}
ind_fed <- ind_fed[2:length(ind_fed)]

# locate the observations that have NA's in marital
ind_marital <- NA
for (ii in 1:length(birth$marital)) {
  if (is.na(birth$marital[ii])) {
    ind_marital <- c(ind_marital, ii)
  }
}
ind_marital <- ind_marital[2:length(ind_marital)]


# locate the observations that have NA's in BMI
ind_BMI <- NA
for (ii in 1:length(birth$BMI)) {
  if (is.na(birth$BMI[ii])) {
    ind_BMI <- c(ind_BMI, ii)
  }
}
ind_BMI <- ind_BMI[2:length(ind_BMI)]

missing <- c(ind_gestation, ind_mage, ind_BMI, ind_marital, ind_fage, ind_fed, ind_med)


# remove missing observations

# first remove duplicated numbers in the missing list
m <- length(missing)
new_missing <- NA
for (ii in 1:m) {
  if (missing[ii] %in% new_missing == FALSE) {
    new_missing <- c(new_missing, missing[ii])
  }
}
new_missing <- new_missing[2:length(new_missing)]



# remove observations containing NA's
birth <- birth[-new_missing,]

```

```{r, label = "pair plot", echo = FALSE, fig.pos = "!htb", out.width = "\\textwidth", fig.cap = "Pair Plot"}
# Figure 1. Pair plots of wt and other continuous numerical variables
pairs(~ wt + gestation + parity + mage + BMI + fage, 
      pch = 19,
      cex = 0.05,
      data = birth)
```

## Automated Model Selection
We constructed our minimal and maximal models for automated model selection (see \ref{maxmin}), where in the maximal model, we removed some interaction effect since they do not give meaningful coefficients but we added main effects. Then, we ran the forward, backward and stepwise selection (see \ref{AMS}). By comparing the models generated by the above selections (see \ref{3models}), it turned out that backward and stepwise selection produced the same model; thus, we decided to keep the models generated by *forward* selection and *stepwise* selection for closer inspection. 

# Model Diagnostics

## Different Residual Plots, Influences and Leverages for M1(foward selection) and M2(stepwise selection)
We plotted the ordinary residuals, standardized residuals, PRESS residuals and DIFFITS residuals against the predicted values and against the leverages for both M1 and M2. Besides, we plotted the QQ-plot for both M1 and M2.
```{r, echo = FALSE}
# Minimal model
M0 <- lm(wt ~ 1, data = birth)

# new maximal model
Mmaxnew <- lm(wt ~ (.-fed - med - feth - meth - marital - smoke_number)^2 
              + smoke_number + feth + meth + fed + med + marital 
              + I(gestation^2), data = birth)

# Automated Model Selection
# Forward selection
  Mfwd <- step(object = M0, # starting point model
               scope = list(lower = M0, upper = Mmaxnew), # smallest and largest model
               direction = "forward",
               trace = FALSE) # trace prints out information

# Backward elimination
  Mback <- step(object = Mmaxnew, # starting point model
                scope = list(lower = M0, upper = Mmaxnew),
                direction = "backward", trace = FALSE)

# Stepwise selection
Mstart <- lm(wt ~ ., data = birth)
  Mstep <- step(object = Mstart,
                scope = list(lower = M0, upper = Mmaxnew),
                direction = "both", trace = FALSE)


```


```{r, label = "ordinary residuals M1 and M2", echo = FALSE, fig.pos = "!htb", out.width = "\\textwidth", fig.height = 3.5, fig.cap = "M1 and M2 Ordinary Residuals vs. Predicted Values"}
# Figure 2
# plot setup
cex <- .8
pch <- 20
par(mfrow = c(1,2), mar = c(4,4,1,1))

# assign new name to Mfwd and Mstep
M1 <- Mfwd
M2 <- Mback

# residuals for M1 and M2
res1 <- residuals(M1)
res2 <- residuals(M2)

# extract sigma.hat for both M1 and M2
sigma.hat1 <- sigma(M1)
sigma.hat2 <- sigma(M2)

# plot ordinary residuals for M1
plot(predict(M1), residuals(M1), pch = pch, cex = cex, col = "black", 
     main = "M1 Residual Plot ")
abline(h = 0, col = "red", lty = 2) # horizontal line

# plot ordinary residuals for M2
plot(predict(M2), residuals(M2), pch = pch, cex = cex, col = "black", 
     main = "M2 Residual Plot ")
abline(h = 0, col = "red", lty = 2) # horizontal line
```

```{r, label = "QQ-plot", echo = FALSE, fig.pos = "!htb", fig.height = 2.5, out.width = "\\textwidth", fig.cap = "M1 and M2 QQ-plots"}
# Figure 3
# plot setup
cex <- .8
pch <- 16
par(mfrow = c(1,2), mar = c(4,4,1,1))

# QQ-plot for M1
qqnorm(res1, main = "M1 QQ-Plot", cex = cex, pch = pch)
qqline(res1, col = "red", lty = 2)

# QQ-plot for M2
qqnorm(res2, main = "M2 QQ-Plot", cex = cex, pch = pch)
qqline(res2, col = "red", lty = 2)

```

```{r, label = "leverage", echo = FALSE, fig.pos = "!htb", fig.height = 2.5, out.width = "\\textwidth", fig.cap = "Predicted Value vs Residuals and Leverages for M1 and M2"}
# Figure 4 and Figure 5
# plot setup
cex <- .8
pch <- 16
par(mfrow = c(1,2), mar = c(4,4,1,1))

# Predicted Value vs Residuals and Leverages for M1

h1 <- hatvalues(M1)  # HAT Matrix
stan.res1 <- res1/sigma.hat1 # Standardized residuals for M1

# PRESS residuals
press1 <- res1/(1-h1)

# DFFITS residuals
dfts1 <- dffits(M1) # the R way
# standardize each of these such that they are identical at the average leverage value
p1 <- length(coef(M1))
n1 <- nobs(M1)
hbar1 <- p1/n1 # average leverage
press1 <- press1*(1-hbar1)/sigma.hat1 # at h1 = hbar1, press1 = stan.res1
dfts1 <- dfts1*(1-hbar1)/sqrt(hbar1) # at h1 = hbar1, dfts1 = stan.res1

# plot all residuals
# against predicted values
plot(predict(M1), rep(0, length(predict(M1))), type = "n", # empty plot to get the axis range
     ylim = range(stan.res1, press1, dfts1), cex.axis = cex,
     xlab = "M1 Predicted Values", ylab = "M1 Residuals")
# dotted line connecting each observations residuals for better visibility
segments(x0 = predict(M1),
         y0 = pmin(stan.res1, press1, dfts1),
         y1 = pmax(stan.res1, press1, dfts1),
         lty = 2)
points(predict(M1), stan.res1, pch = 21, bg = "black", cex = cex)
points(predict(M1), press1, pch = 21, bg = "red", cex = cex)
points(predict(M1), dfts1, pch = 21, bg = "orange", cex = cex)
# against leverages
plot(h1, rep(0, length(predict(M1))), type = "n", cex.axis = cex,
     ylim = range(stan.res1, press1, dfts1),
     xlab = "M1 Leverages", ylab = "M1 Residuals")
segments(x0 = h1,
         y0 = pmin(stan.res1, press1, dfts1),
         y1 = pmax(stan.res1, press1, dfts1),
         lty = 2)
points(h1, stan.res1, pch = 21, bg = "black", cex = cex)
points(h1, press1, pch = 21, bg = "red", cex = cex)
points(h1, dfts1, pch = 21, bg = "orange", cex = cex)
abline(v = hbar1, col = "grey60", lty = 2)
legend("topright", legend = c("Standardized", "PRESS", "DFFITS"),
       pch = 21, pt.bg = c("black", "red", "orange"), title = "Residual Type:",
       cex = cex, pt.cex = cex)


# Figure 5
# Predicted Value vs Residuals and Leverages for M2
h2 <- hatvalues(M2)  # HAT Matrix for M2
stan.res2 <- res1/sigma.hat2 # Standardized residuals for M2

# PRESS residuals
press2 <- res2/(1-h2)

# DFFITS residuals
dfts2 <- dffits(M2) 
# standardize each of these such that they are identical at the average leverage value
p2 <- length(coef(M2))
n2 <- nobs(M2)
hbar2 <- p2/n2 # average leverage
press2 <- press2*(1-hbar2)/sigma.hat2 # at h = hbar2, press2 = stan.res
dfts2 <- dfts2*(1-hbar2)/sqrt(hbar2) # at h = hbar2, dfts2 = stan.res

# plot all residuals
par(mfrow = c(1,2), mar = c(4,4,.1,.1))
# against predicted values
plot(predict(M2), rep(0, length(predict(M2))), type = "n", # empty plot to get the axis range
     ylim = range(stan.res2, press2, dfts2), cex.axis = cex,
     xlab = "M2 Predicted Values", ylab = "M2 Residuals")
# dotted line connecting each observations residuals for better visibility
segments(x0 = predict(M2),
         y0 = pmin(stan.res2, press2, dfts2),
         y1 = pmax(stan.res2, press2, dfts2),
         lty = 2)
points(predict(M2), stan.res2, pch = 21, bg = "black", cex = cex)
points(predict(M2), press2, pch = 21, bg = "red", cex = cex)
points(predict(M2), dfts2, pch = 21, bg = "orange", cex = cex)
# against leverages
plot(h2, rep(0, length(predict(M2))), type = "n", cex.axis = cex,
     ylim = range(stan.res2, press2, dfts2),
     xlab = "M2 Leverages", ylab = "M2 Residuals")
segments(x0 = h2,
         y0 = pmin(stan.res2, press2, dfts2),
         y1 = pmax(stan.res2, press2, dfts2),
         lty = 2)
points(h2, stan.res2, pch = 21, bg = "black", cex = cex)
points(h2, press2, pch = 21, bg = "red", cex = cex)
points(h2, dfts2, pch = 21, bg = "orange", cex = cex)
abline(v = hbar2, col = "grey60", lty = 2)
legend("topright", legend = c("Standardized", "PRESS", "DFFITS"),
       pch = 21, pt.bg = c("black", "red", "orange"), title = "Residual Type:",
       cex = cex, pt.cex = cex)
```

```{r, label = "cooks", echo = FALSE, fig.pos = "!htb", fig.height = 2.4, out.width = "\\textwidth", fig.cap = "Cook's Distance vs Leverage"}
# Figure 6
# plot setup
cex <- .8
pch <- 20
par(mfrow = c(1,2), mar = c(4,4,1,1))

# cook’s distance vs. leverage for M1
D1 <- cooks.distance(M1)
# flag some of the points
infl.ind1 <- which.max(D1) # top influence point
lev.ind1 <- h1 > 2*hbar1 # leverage more than 2x the average
clrs1 <- rep("black", len = n1)
clrs1[lev.ind1] <- "blue"
clrs1[infl.ind1] <- "red"
plot(h1, D1, xlab = "M1 Leverage", ylab = "M1 Cook's Influence Measure",
     pch = 21, bg = clrs1, cex = cex, cex.axis = cex)
p1 <- length(coef(M1))
n1 <- nrow(birth)
hbar1 <- p1/n1 # average leverage
abline(v = 2*hbar1, col = "grey60", lty = 2) # 2x average leverage
legend("topleft", legend = c("High Leverage", "High Influence"), pch = 21,
       pt.bg = c("blue", "red"), cex = cex, pt.cex = cex)

# cook’s distance vs. leverage for M2
D2 <- cooks.distance(M2)
# flag some of the points
infl.ind2 <- which.max(D2) # top influence point
lev.ind2 <- h2 > 2*hbar2 # leverage more than 2x the average
clrs2 <- rep("black", len = n1)
clrs2[lev.ind2] <- "blue"
clrs2[infl.ind2] <- "red"
plot(h2, D2, xlab = "M2 Leverage", ylab = "M2 Cook's Influence Measure",
     pch = 21, bg = clrs2, cex = cex, cex.axis = cex)
p2 <- length(coef(M2))
n2 <- nrow(birth)
hbar2 <- p2/n2 # average leverage
abline(v = 2*hbar2, col = "grey60", lty = 2) # 2x average leverage
legend("topleft", legend = c("High Leverage", "High Influence"), pch = 21,
       pt.bg = c("blue", "red"), cex = cex, pt.cex = cex)
```
## Cross-validation
We ran the cross-validation for both M1(Mfwd) and M2(Mstep) (see \ref{cross-validation}), We produced boxplots for root mean square prediction error(rPMSE), and we calculated the Akaike Information Criterion(AIC) and produced the boxplots for PRESS statistics (see \ref{AIC})

```{r, echo= FALSE}
# Compare M1 and M2
Mnames <- expression(M[1], M[2])
# Cross-validation setup
nreps <- 2e3 # number of replications
ntot <- nrow(birth) # total number of observations
ntrain <- 500 # size of training set
ntest <- ntot-ntrain # size of test set
mspe1 <- rep(NA, nreps) # sum-of-square errors for each CV replication
mspe2 <- rep(NA, nreps)
logLambda <- rep(NA, nreps) # log-likelihod ratio statistic for each replication
  for(ii in 1:nreps) {
    # randomly select training observations
    train.ind <- sample(ntot, ntrain) # training observations
    # refit the models on the subset of training data; ?update for details!
    M1.cv <- update(M1, subset = train.ind)
    M2.cv <- update(M2, subset = train.ind)
    # out-of-sample residuals for both models
    # that is, testing data - predictions with training parameters
    M1.res <- birth$wt[-train.ind] -
      predict(M1.cv, newdata = birth[-train.ind,])
    M2.res <- birth$wt[-train.ind] -
      predict(M2.cv, newdata = birth[-train.ind,])
    # mean-square prediction errors
    mspe1[ii] <- mean(M1.res^2)
    mspe2[ii] <- mean(M2.res^2)
    # out-of-sample likelihood ratio
    M1.sigma <- sqrt(sum(resid(M1.cv)^2)/ntrain) # MLE of sigma
    M2.sigma <- sqrt(sum(resid(M2.cv)^2)/ntrain)
    # since res = y - pred, dnorm(y, pred, sd) = dnorm(res, 0, sd)
    logLambda[ii] <- sum(dnorm(M1.res, mean = 0, sd = M1.sigma, log = TRUE))
    logLambda[ii] <- logLambda[ii] -
      sum(dnorm(M2.res, mean = 0, sd = M2.sigma, log = TRUE))
  }
```

```{r, label = "rPMSE", echo = FALSE, fig.pos = "!htb", fig.height = 3.5, out.width = "\\textwidth", fig.cap = "Cross-validation model comparison results. Left: Root mean square prediction error (rMSPE). Right: Out-of-sample likelihood ratio statistic."}

# Figure 7
# plot setup
cex <- .8
pch <- 16
par(mfrow = c(1,2), mar = c(4,4,1,1))

# plot rMSPE and out-of-sample log(Lambda)
boxplot(x = list(sqrt(mspe1), sqrt(mspe2)), names = Mnames, cex = .7,
        ylab = expression(sqrt(MSPE)), col = c("yellow", "orange"))

hist(logLambda, breaks = 50, freq = FALSE,
     xlab = expression(Lambda^{test}),
     main = "", cex = .7)
abline(v = mean(logLambda), col = "red") # average value
```

```{r, label = "PRESS", echo = FALSE, fig.pos = "!htb", fig.height = 3.5, out.width = "\\textwidth",fig.cap = "Boxplot of squared PRESS statistics for models M1 and M2."}
# Figure 8
# plot setup
cex <- .8
pch <- 16
par(mfrow = c(1,2), mar = c(5,5,1,1))

# PRESS Statistics
# PRESS statistics
press1 <- res1/(1-hatvalues(M1)) # M1
press2 <- res2/(1-hatvalues(M2)) # M2

# plot PRESS statistics
boxplot(x = list(abs(press1), abs(press2)), names = Mnames,
        ylab = expression(group("|", PRESS[i], "|")),
        col = c("yellow", "orange"))

```
Based on the graphs, it could be seen that, for the two candidate models, different residual plots, influence and leverages (Figures 2-6) did not show a big difference; however, it was the boxplots for root mean square prediction error(rPMSE) and the Akaike Information of the two models that showed us M2(stepwise model) is the better one (Figure 7 and 8). Hence, we decided to choose the stepwise model, Mstep, as our final model (see \ref{Mstep})

# Discussion

## Deficiency
Since we threw out close to 10% of the entire observations, it could create bias in our analysis. Plus, we imputed missing mother's ethnicity (meth) and father's ethnicity (feth) by matching misssing ethnicity in one parent with the one of the other parent, which could also create bias. 
\clearpage

\appendix

# R code

## Summary of the dataset {#summary}
```{r}
getwd() # make sure that the file is in the working directory

# load the data as a data.frame
birth <- read.csv(file = "chds_births.csv")

# summary of data
summary(birth)
```

## {#NA}
```{r}
# throw out fht, fwt and income
birth <- birth[,-c(12, 13, 15)]
```

## Check how many observations contain NA's {#countNA}
```{r}
n <- length(birth$wt) # number of rows
count <- 0 # initialize count of rows with at least one NA
for (ii in 1:n) {
  if(sum(is.na(birth[ii,])) >= 1) {
    count = count + 1
  }
}
total_NA_rows <- count
total_NA_rows
```

## Regroup the variable number {#number}
```{r}
# create new descriptive groups for number of cigarettes smoked per day

num2 <- birth$number
# new categories for variable number
numnames <- c("never smoked", "up to half a pack", "half to full pack", "more than one pack")

for(ii in 0:9) {
  if(ii==0) {
    num2[num2 == ii] <- numnames[1]
  } 
  if(0 < ii & ii <= 2) {
    num2[num2 == ii] <- numnames[2]
  } 
  if(2 < ii & ii <= 4) {
    num2[num2 == ii] <- numnames[3]
  } else {
    num2[num2 == ii] <- numnames[4]
  }
}

birth$number <- num2 # replace in dataset
```

## Regroup the variable smoke in terms of time {#smoketime}
```{r}
# combine smoke and time into a single variable smoke (relabelling smoke):
# create categories for new variables
newnames <- c("Never Smoked", "Still Smokes",
              "Smoked but quit during pregnancy", 
              "Smoked but quit before pregnancy")

# extract the corresponding columns
smoke <- birth$smoke

n <- length(smoke) # number of observations
newsmoke <- rep(NA, n)

for (ii in 1:n) {
  if (is.na(smoke[ii])) {
    newsmoke[ii] <- NA
  }
  else {
    for (jj in 0:3) {
      if (smoke[ii] == jj) {
        newsmoke[ii] <- newnames[jj+1]
      }
    }
  }
}
birth$smoke <- newsmoke
```

## Remove observations containing NA's in smoke and number {#removesmokenumber}
```{r}
# locate the observations that have NA's in smoke
ind_smoke <- NA
for (ii in 1:length(birth$smoke)) {
  if (is.na(birth$smoke[ii])) {
    ind_smoke <- c(ind_smoke, ii)
  }
}
ind_smoke <- ind_smoke[2:length(ind_smoke)]

# locate the observations that have NA's in number
ind_number <- NA
for (ii in 1:length(birth$number)) {
  if (is.na(birth$number[ii])) {
    ind_number <- c(ind_number, ii)
  }
}
ind_number <- ind_number[2:length(ind_number)]

# Throw out the observations that have NA's in smoke and number
# note that observations that have NA's in smoke also have NA's in number
remove_smoke <- ind_number
birth <- birth[-remove_smoke,]
```

## Create the new variable smoke_number {#smoke_number}
```{r}
# create a new variable to combine smoke and number
# note that nobody is in the category "Smoked up to half a pack but quit during pregnancy"

smoke_number <- birth$smoke
for (ii in 1:(length(birth$smoke))) {
  if (smoke_number[ii] != "Never Smoked") {
    if (birth$number[ii] == "up to half a pack") {
      if (smoke_number[ii] == "Smoked but quit before pregnancy") {
        smoke_number[ii] <- "Smoked up to half a pack but quit before pregnancy"
      }
      else {smoke_number[ii] <- "Still smokes up to half a pack"}
    }
    else if (birth$number[ii] == "half to full pack") {
      if (smoke_number[ii] == "Smoked but quit before pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit before pregnancy"
      }
      else if (smoke_number[ii] == "Smoked but quit during pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit during pregnancy"
      }
      else {smoke_number[ii] <- "Still smokes half to full pack"}
    }
    else {
      if (smoke_number[ii] == "Smoked but quit before pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit before pregnancy"
      }
      else if (smoke_number[ii] == "Smoked but quit during pregnancy") {
        smoke_number[ii] <- "Smoked more than half a pack but quit during pregnancy"
      }
      else {smoke_number[ii] <- "Still smokes more than one pack"}
    }
  }
}

# factor the new variable smoke_number
birth$smoke_number <- factor(smoke_number)
```

## Remove the original smoke, time and number {#smoketimenumber}
```{r}
# Remove the original smoke, time and number
birth <- birth[,-c(13, 14, 15)]
```

## BMI {#BMI}
```{r}
# Combine mht and mwt to create a new variable BMI
# BMI is called Body Mass Index, which is calculated by weight in kg / height^2 in m
# Convert mht and mwt to standard metric
lbs_to_kg <- 0.453592
birth$mwt <- lbs_to_kg * birth$mwt
inch_to_meter <- 0.0254
birth$mht <- inch_to_meter * birth$mht

# Create BMI variable
mht <- birth$mht
mwt <- birth$mwt
BMI <- mwt / mht^2
birth$BMI <- BMI
```

## {#removemhtmwt}
```{r}
# throw out mht and mwt
birth <- birth[,-c(7, 8)]
```

## {#othermixed}
```{r}
# Combine other and mixed in feth and call it other
for (ii in 1:length(birth$feth)) {
  if (!is.na(birth$feth[ii])) {
    if(birth$feth[ii] == 10) {
      birth$feth[ii] <- 9
    }
  }
}

# Combine other and mixed in meth and call it other
for (ii in 1:length(birth$meth)) {
  if (!is.na(birth$meth[ii])) {
    if(birth$meth[ii] == 10) {
      birth$meth[ii] <- 9
    }
  }
}

```

## {#countethnicity}
```{r}
# Want to count how many rows have meth=feth
count.eth <- 0
for (ii in 1:length(birth$meth)) {
  if ((is.na(birth$feth[ii])==FALSE) & is.na(birth$meth[ii])==FALSE){
    if (birth$meth[ii]<=5) {
      if (birth$feth[ii]<=5){
        count.eth <- count.eth+1
      }
    }
    else {
      if (birth$meth[ii]==birth$feth[ii]){
        count.eth <- count.eth+1
      }
    }
  }
}
count.eth
```

## Factor all categorical variables {#factor}
### meth
```{r}
# convert categorical variables to factors

# convert meth to non-numeric categorical variable
meth2 <- birth$meth
length(meth2)
# "levels" of variable meth
methnames <- c("Caucasian","Mexican", "African-American","Asian", "Other")
# assign "Caucasian" level to values less than or equal to 5
# otherwise assign levels based on order in methnames vector
for(ii in 0:9) {
  if(ii<=5){
    meth2[meth2 == ii] <- "Caucasian"
  } else {
    meth2[meth2 == ii] <- methnames[ii-4]
  }
}
meth2 <- factor(meth2, levels = methnames) # order levels based on methnames
levels(meth2)
birth$meth <- meth2 # replace in dataset
############################################
```

### med
```{r}
# convert med to categorical variables
med2 <- birth$med
# "levels" of variable med
mednames <- c("elementary school", "middle school", "high school", "high school + trade", "high school + some college", "college grad", "trade school", "high school unclear")
med2 <- mednames[birth$med+1]
med2 <- factor(med2, levels = mednames) # order levels based on mednames
levels(med2)
birth$med <- med2 # replace in dataset
```

### feth
```{r}
# convert feth to categorical variables
feth2 <- birth$feth
# "levels" of variable feth
fethnames <- c("Caucasian","Mexican", "African-American","Asian", "Other")
# assign "Caucasian" level to values less than or equal to 5
# otherwise assign levels based on order in fethnames vector
for(ii in 0:9) {
  if(ii<=5){
    feth2[feth2 == ii] <- "Caucasian"
  } else {
    feth2[feth2 == ii] <- fethnames[ii-4]
  }
}
feth2 <- factor(feth2, levels = fethnames) # order levels based on methnames
levels(feth2)
birth$feth <- feth2 # replace in dataset
```

### fed
```{r}
# convert fed to categorical variables
fed2 <- birth$fed
# "levels" of variable fed
fednames <- c("elementary school", "middle school", "high school", "high school + trade", "high school + some college", "college grad", "trade school", "high school unclear")
fed2 <- fednames[birth$fed+1]
fed2 <- factor(fed2, levels = fednames) # order levels based on fednames
levels(fed2)
birth$fed <- fed2 # replace in dataset
```


### marital
```{r}
marital <- birth$marital
maritalnames <- c("married", "legally separated", "divorced", "widowed",
                  "never married") # new values
# encode the factor
marital2 <- rep(NA, length(marital))
for (ii in 1:5) {
  marital2[marital == ii] <- maritalnames[ii]
}
marital2 <- factor(marital2, levels = maritalnames)
birth$marital <- marital2
```

## Imputing meth and feth {#ethNA}
```{r}
# we assume fathers and mothers have the same ethnicity background
# based on the majority of the dataset
# deal with the NA's in meth
for (ii in 1:length(birth$meth)) {
  if(is.na(birth$meth)[ii]) {
    birth$meth[ii] <- birth$feth[ii]
  }
}

# deal with the NA's in feth
for (ii in 1:length(birth$feth)) {
  if(is.na(birth$feth)[ii]) {
    birth$feth[ii] <- birth$meth[ii]
  }
}
```


## {#removeNA}
```{r}
# locate the observations that have NA's in gestation
ind_gestation <- NA
for (ii in 1:length(birth$gestation)) {
  if (is.na(birth$gestation[ii])) {
    ind_gestation <- c(ind_gestation, ii)
  }
}
ind_gestation <- ind_gestation[2:length(ind_gestation)]

# locate the observations that have NA's in mage
ind_mage <- NA
for (ii in 1:length(birth$mage)) {
  if (is.na(birth$mage[ii])) {
    ind_mage <- c(ind_mage, ii)
  }
}
ind_mage <- ind_mage[2:length(ind_mage)]

# locate the observations that have NA's in med
ind_med <- NA
for (ii in 1:length(birth$med)) {
  if (is.na(birth$med[ii])) {
    ind_med <- c(ind_med, ii)
  }
}
ind_med <- ind_med[2:length(ind_med)]

# locate the observations that have NA's in fage
ind_fage <- NA
for (ii in 1:length(birth$fage)) {
  if (is.na(birth$fage[ii])) {
    ind_fage <- c(ind_fage, ii)
  }
}
ind_fage <- ind_fage[2:length(ind_fage)]

# locate the observations that have NA's in fed
ind_fed <- NA
for (ii in 1:length(birth$fed)) {
  if (is.na(birth$fed[ii])) {
    ind_fed <- c(ind_fed, ii)
  }
}
ind_fed <- ind_fed[2:length(ind_fed)]

# locate the observations that have NA's in marital
ind_marital <- NA
for (ii in 1:length(birth$marital)) {
  if (is.na(birth$marital[ii])) {
    ind_marital <- c(ind_marital, ii)
  }
}
ind_marital <- ind_marital[2:length(ind_marital)]


# locate the observations that have NA's in BMI
ind_BMI <- NA
for (ii in 1:length(birth$BMI)) {
  if (is.na(birth$BMI[ii])) {
    ind_BMI <- c(ind_BMI, ii)
  }
}
ind_BMI <- ind_BMI[2:length(ind_BMI)]

missing <- c(ind_gestation, ind_mage, ind_BMI, ind_marital, ind_fage, ind_fed, ind_med)
missing

# remove missing observations

# first remove duplicated numbers in the missing list
m <- length(missing)
new_missing <- NA
for (ii in 1:m) {
  if (missing[ii] %in% new_missing == FALSE) {
    new_missing <- c(new_missing, missing[ii])
  }
}
new_missing <- new_missing[2:length(new_missing)]

# display the indexes of all observations with NA's
new_missing

# remove observations containing NA's
birth <- birth[-new_missing,]
```

## Pair Plot {#pairplot}
```{r, ref.label = "pair plot", eval = FALSE}
```

## Max and min modes {#maxmin}
```{r}
# Minimal model
M0 <- lm(wt ~ 1, data = birth)
summary(M0)


# new maximal model
Mmaxnew <- lm(wt ~ (.-fed - med - feth - meth - marital - smoke_number)^2 
              + smoke_number + feth + meth + fed + med + marital 
              + I(gestation^2), data = birth)
summary(Mmaxnew)

beta.maxnew <- coef(Mmaxnew)
names(beta.maxnew)[is.na(beta.maxnew)]
anyNA(coef(Mmaxnew))
```

## AMS {#AMS}
```{r}
# Automated Model Selection
# Forward selection
system.time({ # time the calculation
  Mfwd <- step(object = M0, # starting point model
               scope = list(lower = M0, upper = Mmaxnew), # smallest and largest model
               direction = "forward",
               trace = FALSE) # trace prints out information
})

# Backward elimination
system.time({
  Mback <- step(object = Mmaxnew, # starting point model
                scope = list(lower = M0, upper = Mmaxnew),
                direction = "backward", trace = FALSE)
})

# Stepwise selection
Mstart <- lm(wt ~ ., data = birth)
system.time({
  Mstep <- step(object = Mstart,
                scope = list(lower = M0, upper = Mmaxnew),
                direction = "both", trace = FALSE)
})
```

## Mfwd, Mback and Mstep {#3models}
```{r}
Mfwd$call
Mback$call
Mstep$call
```

## M1 and M2 Ordinary Residuals vs. Prediected Values
```{r, ref.label = "ordinary residuals M1 and M2", eval = FALSE}
```

## M1 and M2 QQ-plots
```{r, ref.label = "QQ-plot", eval = FALSE}
```

## M1 and M2 Predicted Value vs Residuals and Leverages
```{r, ref.label = "leverage", eval = FALSE}
```

## M1 and M2 Cook's Distance vs Leverage
```{r, ref.label = "cooks", eval = FALSE}
```

## Cross-Validation {#cross-validation}
```{r}
# models to compare
M1 <- Mfwd
M2 <- Mstep
Mnames <- expression(M[FWD], M[STEP])
# Cross-validation setup
nreps <- 2e3 # number of replications
ntot <- nrow(birth) # total number of observations
ntrain <- 500 # size of training set
ntest <- ntot-ntrain # size of test set
mspe1 <- rep(NA, nreps) # sum-of-square errors for each CV replication
mspe2 <- rep(NA, nreps)
logLambda <- rep(NA, nreps) # log-likelihod ratio statistic for each replication
system.time({
  for(ii in 1:nreps) {
    if(ii%%400 == 0) message("ii = ", ii)
    # randomly select training observations
    train.ind <- sample(ntot, ntrain) # training observations
    # refit the models on the subset of training data; ?update for details!
    M1.cv <- update(M1, subset = train.ind)
    M2.cv <- update(M2, subset = train.ind)
    # out-of-sample residuals for both models
    # that is, testing data - predictions with training parameters
    M1.res <- birth$wt[-train.ind] -
      predict(M1.cv, newdata = birth[-train.ind,])
    M2.res <- birth$wt[-train.ind] -
      predict(M2.cv, newdata = birth[-train.ind,])
    # mean-square prediction errors
    mspe1[ii] <- mean(M1.res^2)
    mspe2[ii] <- mean(M2.res^2)
    # out-of-sample likelihood ratio
    M1.sigma <- sqrt(sum(resid(M1.cv)^2)/ntrain) # MLE of sigma
    M2.sigma <- sqrt(sum(resid(M2.cv)^2)/ntrain)
    # since res = y - pred, dnorm(y, pred, sd) = dnorm(res, 0, sd)
    logLambda[ii] <- sum(dnorm(M1.res, mean = 0, sd = M1.sigma, log = TRUE))
    logLambda[ii] <- logLambda[ii] -
      sum(dnorm(M2.res, mean = 0, sd = M2.sigma, log = TRUE))
  }
})
```

## M1 and M2 rPMSE
```{r, ref.label = "rPMSE", eval = FALSE}
```

## AIC for M1 and M2 {#AIC}
```{r}
# Akaike Information Criterion
# calculate the values AIC1 and AIC2
AIC1 <- AIC(M1)
AIC2 <- AIC(M2)
# display the results
AIC <- c(AIC1, AIC2)
AIC

# display results for both AIC and PRESS
disp <- rbind(AIC = c(AIC1, AIC2),
              PRESS = c(sum(press1^2), sum(press2^2)))
colnames(disp) <- Mnames
disp # both metrics favor M2
```

## PRESS statistics
```{r, ref.label = "PRESS", eval = FALSE}
```

## Final candidate model: Mstep {#Mstep}
```{r}
summary(Mstep)
```




